太棒了！我们继续前进，接下来是操作系统中非常关键的几个模块：**处理机调度、死锁、存储管理（包括虚拟存储器）、I/O系统 和 文件管理**。这部分内容理论性、实践性都很强，并且包含一些计算题型，是考试的重中之重，也是你冲击90分必须牢牢掌握的部分。

---

### 第四部分：处理机调度与死锁 (对应 P5, P6, P7 的题目)

这部分关注如何有效地分配CPU资源给各个进程/作业，以及如何处理并发执行中可能出现的“僵局”——死锁。

**1. 调度 (Scheduling) 的基本概念和层次 (对应 P5 Q1)**

*   **什么是调度？** 在多道程序环境下，内存中通常有多个进程，但CPU在某一时刻只能运行一个。**调度**就是操作系统按照某种策略（调度算法），从就绪队列中选择一个进程，将CPU的使用权分配给它。
*   **调度的三个层次**：
    *   **高级调度 (High-Level Scheduling) / 作业调度 (Job Scheduling)**：
        *   **任务**：决定将哪些在外存**后备队列**中的**作业**调入内存，为其创建进程，分配必要的资源（除了CPU），并使其进入**就绪**状态。
        *   **作用对象**：作业。
        *   **发生频率**：较低，在作业提交和完成时发生。
        *   **主要目标**：控制进入系统的**多道程序度 (Degree of Multiprogramming)**，平衡系统负载。
    *   **低级调度 (Low-Level Scheduling) / 进程调度 / CPU调度 (Process/CPU Scheduling)**：
        *   **任务**：按照某种算法（如FCFS, RR, Priority等），从**内存中的就绪队列**中选择一个**进程**，并将CPU分配给它。
        *   **作用对象**：进程（或内核级线程）。
        *   **发生频率**：**非常高**，在时钟中断、I/O中断、进程阻塞/终止时都可能发生。是OS最基本的功能之一。
        *   **主要目标**：高效利用CPU，快速响应用户请求。
    *   **中级调度 (Medium-Level Scheduling) / 内存调度 / 交换 (Swapping)**：
        *   **引入原因**：为了提高内存利用率和系统吞吐量。当内存紧张时，可以将某些暂时不能运行的进程（如阻塞态进程，或优先级低的就绪态进程）从**内存**换出到**外存**（挂起状态），腾出内存空间。当条件允许时，再将它们换回内存，恢复到原来的状态（就绪或阻塞）。
        *   **任务**：决定将哪些进程换出（挂起 Swapped Out）、哪些进程换入（激活 Swapped In）。
        *   **作用对象**：进程。
        *   **发生频率**：介于高级和低级之间。

    ```mermaid
    graph TD
        subgraph "外存 (Disk)"
            BackupQueue["后备作业队列"]
        end
        subgraph "内存 (Memory)"
            ReadyQueue["就绪队列"]
            Running["运行态"]
            BlockedQueue["阻塞队列"]
            SuspendedReady["挂起就绪态 (在外存)"]
            SuspendedBlocked["挂起阻塞态 (在外存)"]
        end

        BackupQueue -- "高级调度 (调入)" --> ReadyQueue
        ReadyQueue -- "低级调度 (选中)" --> Running
        Running -- "时间片完/抢占" --> ReadyQueue
        Running -- "等待事件" --> BlockedQueue
        BlockedQueue -- "事件发生" --> ReadyQueue
        Running -- "作业完成/终止" --> ExitState("终止态")

        ReadyQueue -- "中级调度 (换出)" --> SuspendedReady
        BlockedQueue -- "中级调度 (换出)" --> SuspendedBlocked
        SuspendedReady -- "中级调度 (换入)" --> ReadyQueue
        SuspendedBlocked -- "中级调度 (换入，事件未发生)" --> BlockedQueue
        SuspendedBlocked -- "事件发生 (在外存)" --> SuspendedReady

        style SuspendedReady fill:#ddd,stroke:#333
        style SuspendedBlocked fill:#ddd,stroke:#333
    ```

**2. 处理机调度算法的目标 (对应 P5 Q2)**

选择调度算法时，需要考虑很多目标，有时这些目标会相互冲突。

*   **共同目标 (Common Goals)**：
    *   **CPU利用率 (CPU Utilization)**：让CPU尽可能忙碌，越高越好。
    *   **系统吞吐量 (System Throughput)**：单位时间内完成的进程（或作业）数量，越多越好。
    *   **周转时间 (Turnaround Time)**：从进程（或作业）提交到完成所花费的总时间（= 等待时间 + 执行时间 + I/O时间），越短越好。
        *   平均周转时间：所有进程周转时间之和 / 进程数。
        *   带权周转时间 (Weighted Turnaround Time)：周转时间 / 执行时间。衡量相对等待时间，比值越小越好（接近1最好）。
        *   平均带权周转时间：所有进程带权周转时间之和 / 进程数。
    *   **等待时间 (Waiting Time)**：进程在就绪队列中等待CPU所花费的时间总和，越短越好。
    *   **响应时间 (Response Time)**：从用户提交请求（或交互式输入）到系统首次产生响应所花费的时间，越快越好（主要针对交互式系统）。
*   **批处理系统的调度目标 (Batch System Goals)** (P5 Q2 后半问)：
    *   **高系统吞吐量**：希望尽快完成一批作业。
    *   **短平均周转时间**：用户希望作业尽快完成。
    *   **高CPU利用率**：充分利用昂贵的CPU资源。
    *   (响应时间通常不重要)

**3. 作业调度中的决策 (对应 P5 Q5)**

作业调度要决定：

*   **接纳多少作业？** 主要取决于当前系统的**多道程序度**（内存中同时运行的进程数）。需要平衡，太少则资源利用率低，太多则可能导致内存紧张和进程竞争激烈。
*   **接纳哪些作业？** 这由**作业调度算法**决定，常见的有：
    *   **FCFS (先来先服务)**：按作业到达后备队列的先后顺序选择。简单公平，但可能对短作业不利。
    *   **SJF (短作业优先)**：选择估计运行时间最短的作业。平均周转时间、平均等待时间最优，但可能导致长作业“饿死”。
    *   **Priority (优先级调度)**：选择优先级最高的作业。可以根据紧迫程度、用户付费等设置优先级。可能导致低优先级饿死。
    *   **HRRN (最高响应比优先)**：响应比 R = (等待时间 + 要求服务时间) / 要求服务时间。选择 R 最大的作业。既考虑了等待时间（照顾长作业），也考虑了服务时间（照顾短作业），比较均衡。

**4. CPU调度算法 (重点！涉及 P6, P7 计算题)**

*   **抢占 (Preemption) vs. 非抢占 (Non-preemption)** (P5 Q8 抢占原则)：
    *   **非抢占**：一旦CPU分配给某进程，它将一直运行下去，直到完成、阻塞或自愿放弃CPU。
    *   **抢占**：当前运行的进程可能会被强制暂停，让出CPU给另一个进程。**抢占的原则/时机**通常包括：
        *   **时间片用完** (Round Robin)。
        *   有**更高优先级的进程**变为就绪 (Priority Preemptive)。
        *   (有时) 有**更短剩余时间的进程**变为就绪 (SRTF)。
*   **常用CPU调度算法及其计算**：
    *   **FCFS (First-Come, First-Served)**：按进程到达就绪队列的顺序调度。非抢占。
        *   **优点**：简单、公平。
        *   **缺点**：平均等待时间可能很长，尤其当一个长进程先到达时，后面的短进程需要等很久（称为“护航效应” Convoy Effect）。对I/O密集型进程（执行时间短，频繁I/O）不利。
        *   **计算 (P6 Q2(1), P7 Q3)**：
            1.  画**甘特图 (Gantt Chart)**：按到达时间排序，依次执行。
            2.  计算**完成时间 (Completion Time, CT)**：进程执行结束的时刻。
            3.  计算**周转时间 (Turnaround Time, TAT)** = CT - Arrival Time (AT)。
            4.  计算**等待时间 (Waiting Time, WT)** = TAT - Burst Time (BT)。
            5.  计算**平均值**。
    *   **SJF (Shortest Job First) / SPF (Shortest Process First)**：选择就绪队列中**执行时间最短**的进程。可以是非抢占的，也可以是抢占的。
        *   **SRTF (Shortest Remaining Time First)**：SJF的**抢占**版本。当一个新进程到达就绪队列，如果它的执行时间比当前正在运行进程的**剩余执行时间**还要短，则抢占CPU。
        *   **优点**：平均等待时间、平均周转时间理论上最短。
        *   **缺点**：
            *   需要**预测**执行时间（通常不准确）。
            *   可能导致**长进程饿死** (Starvation)。
            *   抢占式SRTF开销更大（上下文切换）。
        *   **计算 (P7 Q3 - SJF 非抢占)**：
            1.  在每个调度点（进程完成时，或新进程到达时对于SRTF），查看**就绪队列**中所有进程的（剩余）执行时间，选择最短的投入运行。
            2.  画甘特图，计算各项指标。**注意SRTF的抢占点**。
    *   **Priority Scheduling (优先级调度)**：选择**优先级最高**的就绪进程。可以是抢占的，也可以是非抢占的。优先级可以静态或动态确定。
        *   **注意**：题目中通常会说明**优先级的含义**（数值越小优先级越高 还是 数值越大优先级越高）。P6 Q1和Q2都提到“优先数越小，优先级越高”。
        *   **优点**：可以满足不同任务的紧迫性要求。
        *   **缺点**：可能导致**低优先级进程饿死**。解决方法：**老化 (Aging)** - 逐渐提升等待时间较长进程的优先级。
        *   **计算 (P6 Q1 进程调度, P6 Q2(2) - 抢占式)**：
            1.  在每个调度点（进程完成、新进程到达、阻塞进程变就绪、(抢占式)更高优先级到达），检查就绪队列，选择优先级最高的进程。
            2.  如果是**抢占式**，新到达的高优先级进程会**立即抢占**当前运行的低优先级进程。
            3.  画甘特图，计算指标。
    *   **RR (Round Robin, 时间片轮转)**：主要用于**分时系统**。将所有就绪进程按 FCFS 组成队列。每次调度选择队首进程，让它运行一个**时间片 (Time Quantum / Slice)**。
        *   如果进程在时间片内完成，则自愿放弃CPU，调度程序选择下一个。
        *   如果时间片用完但进程未完成，则**计时器中断**，OS将该进程移到**就绪队列末尾**，然后调度队首进程。
        *   **优点**：公平，响应时间较快，不会饿死。
        *   **缺点**：上下文切换开销较大（取决于时间片大小）。时间片太大则退化为FCFS，太小则切换频繁，系统开销大。
        *   **计算 (P6 Q2(3), P7 Q4 进程调度)**：
            1.  维护一个就绪队列。
            2.  按时间片轮转执行，画甘特图。**精确记录**每个进程每次运行的起止时间。
            3.  计算指标。等待时间是每次进入就绪队列到下次被选中的时间总和。
    *   **HRRN (Highest Response Ratio Next, 最高响应比优先)**：非抢占。在每次调度时，计算就绪队列中每个进程的**响应比**，选择**响应比最高**的进程。
        *   `响应比 R = (等待时间 + 要求服务时间) / 要求服务时间 = 1 + (等待时间 / 要求服务时间)`
        *   **优点**：结合了FCFS和SJF的优点。短作业因为服务时间短，容易获得较高响应比；长作业等待时间增加，响应比也会提高，避免了饿死。
        *   **计算 (P7 Q3, P7 Q4 作业调度)**：
            1.  在每个调度点（进程/作业完成时），计算**当前时刻**就绪队列中所有进程/作业的响应比。
            2.  选择 R 最高的投入运行。
            3.  画甘特图，计算指标。

*   **计算题框架/技巧 (非常重要！)**：
    1.  **明确算法类型**：FCFS, SJF/SRTF, Priority(是否抢占), RR, HRRN。
    2.  **明确参数**：到达时间(AT), 执行时间/服务时间(BT), 优先级, 时间片大小(q)。
    3.  **画甘特图 (Gantt Chart)**：这是核心！时间轴，标出每个进程占用CPU的起止时刻。
        *   **起始点**：通常是0时刻，或者第一个进程/作业到达的时刻。
        *   **调度点**：进程完成、新进程到达、(抢占式)更高优先级到达、(RR)时间片用完。在每个调度点，根据算法规则决定下一个运行的进程。
        *   **记录状态**：可以用列表辅助记录每个时刻的就绪队列、运行进程、完成进程。
        *   **细心！** 特别是抢占式算法和RR，时间点和剩余时间的计算要精确。
    4.  **计算指标**：
        *   完成时间 (CT)：甘特图上进程结束的时刻。
        *   周转时间 (TAT) = CT - AT
        *   等待时间 (WT) = TAT - BT (或 = 开始执行时间 - 到达时间 + (后续等待时间总和...对于抢占和RR更复杂，用TAT-BT更方便))
        *   (带权)周转时间 = TAT / BT
    5.  **计算平均值**：各项指标总和 / 进程数。
    6.  **检查！** 确保所有进程都已完成，时间计算无误。

    *   **P6 Q1**：涉及两级调度。作业调度用SJF（非抢占），选计算时间短的先调入内存（最多两道）。进程调度用抢占式优先级（优先数小优先）。需要先确定作业进入内存的时间，再根据进程调度画CPU执行的甘特图。
    *   **P7 Q4**：也涉及两级。作业调度用HRRN。主存空间100K，采用可变分区+最先适应法分配。进程调度用RR。需要先按HRRN和内存情况决定作业调入顺序和时间，再按RR画CPU执行甘特图。这类题综合性强，步骤繁琐，务必细心。

**5. 死锁 (Deadlock) (对应 P5 Q27, Q29, Q31)**

*   **定义 (P5 Q27)**：指两个或多个进程在执行过程中，因争夺资源而造成的一种**互相等待**的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。这些永远在互相等待的进程称为死锁进程。
*   **产生死锁的原因 (P5 Q27)**：
    *   **系统资源不足**。
    *   **进程推进顺序非法**（请求和释放资源的顺序不当）。
*   **产生死锁的四个必要条件 (P5 Q27)**：必须**同时满足**！
    1.  **互斥 (Mutual Exclusion)**：资源在同一时间只能被一个进程使用。
    2.  **占有并等待 (Hold and Wait)**：进程至少保持一个资源，并且正在等待获取其他进程持有的资源。
    3.  **不可抢占 (No Preemption)**：资源不能被强制从持有它的进程中剥夺，只能由进程自愿释放。
    4.  **循环等待 (Circular Wait)**：存在一个进程资源的循环等待链，P0等P1的资源，P1等P2的...Pn等P0的。
*   **处理死锁的方法**：
    *   **死锁预防 (Deadlock Prevention) (P5 Q29)**：通过设置某些限制条件，破坏产生死锁的四个必要条件中的**一个或多个**，从而防止死锁发生。
        *   **破坏互斥**：比较难，有些资源（如打印机）本身就是互斥的。可以尝试把互斥资源虚拟化（如SPOOLing）。
        *   **破坏占有并等待**：
            *   **一次性申请**：进程运行前一次性申请所有所需资源。（资源利用率低，可能饿死）
            *   **只允许在无资源时申请**：要申请新资源，必须先释放所有已持有资源。（实现复杂，可能反复申请释放）
        *   **破坏不可抢占**：
            *   允许系统**抢占**资源。如果一个进程申请不到新资源，则释放已持有资源。（实现复杂，可能导致前段工作失效，代价高）
            *   或者，申请资源被阻塞时，主动释放已持有资源。
        *   **破坏循环等待**：
            *   **资源有序分配法**：将所有资源类型进行线性排序，规定进程必须按序号递增的顺序申请资源。（限制了资源使用灵活性，编号困难）
    *   **死锁避免 (Deadlock Avoidance)**：不限制必要条件，而是在资源分配过程中，使用某种算法（如**银行家算法**）判断本次分配是否会导致系统进入**不安全状态**，如果会，则不予分配，让进程等待。目标是确保系统始终处于**安全状态**。
        *   **安全状态 (Safe State)**：指系统能按某种进程推进顺序 (称为**安全序列**) 为每个进程分配其所需的资源，直至完成。如果不存在这样的序列，则系统处于**不安全状态 (Unsafe State)**。
        *   **不安全状态 ≠ 死锁状态**。进入不安全状态只是**可能**导致死锁。
        *   **银行家算法 (Banker's Algorithm) (P5 Q31)**：适用于**资源数量固定**、**进程最大需求已知**的系统。
            *   **数据结构**：
                *   `Available`: 可用资源向量。`Available[j] = k` 表示 j 类资源现有 k 个。
                *   `Max`: 最大需求矩阵。`Max[i, j] = k` 表示进程 Pi 最多需要 j 类资源 k 个。
                *   `Allocation`: 已分配资源矩阵。`Allocation[i, j] = k` 表示进程 Pi 当前已分得 j 类资源 k 个。
                *   `Need`: 需求矩阵。`Need[i, j] = k` 表示进程 Pi 还需 j 类资源 k 个。 `Need[i, j] = Max[i, j] - Allocation[i, j]`。
            *   **安全性算法 (Safety Algorithm)**：判断系统当前是否安全。
                1.  初始化 `Work = Available`, `Finish[i] = false` for all i.
                2.  **找满足条件的进程 Pi**：`Finish[i] == false` 且 `Need[i] <= Work` (Pi所需资源 <= 当前可用资源)。
                3.  如果找到这样的 Pi：
                    *   `Work = Work + Allocation[i]` (假装执行完，释放资源)
                    *   `Finish[i] = true`
                    *   回到步骤 2。
                4.  如果找不到这样的 Pi：检查是否所有 `Finish[i]` 都为 `true`。
                    *   如果**是**，则系统处于**安全状态**，找到的安全序列就是按 Pi 被选中的顺序。
                    *   如果**否**，则系统处于**不安全状态**。
            *   **资源请求算法 (Resource-Request Algorithm)**：判断进程 Pi 的请求 `Request_i` 能否被满足。
                1.  检查 `Request_i <= Need[i]` (请求是否超需？)。否，则出错。
                2.  检查 `Request_i <= Available` (当前是否有足够资源？)。否，则 Pi 等待。
                3.  **试探性分配**：
                    *   `Available = Available - Request_i`
                    *   `Allocation[i] = Allocation[i] + Request_i`
                    *   `Need[i] = Need[i] - Request_i`
                4.  **调用安全性算法**检查新状态是否安全。
                5.  如果安全，则**正式分配**资源给 Pi。
                6.  如果不安全，则**撤销试探性分配**（恢复 Available, Allocation, Need），让 Pi **阻塞等待**。
            *   **P5 Q31 解题步骤**:
                *   (1) **判断当前状态是否安全**:
                    *   计算 `Need` 矩阵 = `Max` (题目没给Max，但给了Need) - `Allocation`。
                    *   运行**安全性算法**：`Work = Available = (1, 6, 2, 2)`。`Finish = [F, F, F, F, F]`。
                    *   找 `Need[i] <= Work`：
                        *   P0: Need(0,0,1,2) <= (1,6,2,2) ? Yes. -> Work=(1,6,5,4), Finish=[T,F,F,F,F]
                        *   P1: Need(1,7,5,0) <= (1,6,5,4) ? No (7>6).
                        *   P2: Need(2,3,5,6) <= (1,6,5,4) ? No (2>1, 6>4).
                        *   P3: Need(0,6,5,2) <= (1,6,5,4) ? Yes. -> Work=(1,9,8,6), Finish=[T,F,F,T,F]
                        *   P4: Need(0,6,5,6) <= (1,9,8,6) ? Yes. -> Work=(1,9,9,10), Finish=[T,F,F,T,T]
                        *   P1: Need(1,7,5,0) <= (1,9,9,10) ? Yes. -> Work=(2,9,9,10), Finish=[T,T,F,T,T]
                        *   P2: Need(2,3,5,6) <= (2,9,9,10) ? Yes. -> Work=(3,12,14,14), Finish=[T,T,T,T,T]
                    *   所有进程 Finish=True。**系统安全**。安全序列之一：<P0, P3, P4, P1, P2>。
                *   (2) **判断 P2 请求 Request(1,2,2,2) 后是否安全**:
                    *   检查 `Request(1,2,2,2) <= Need[2](2,3,5,6)`? Yes.
                    *   检查 `Request(1,2,2,2) <= Available(1,6,2,2)`? Yes.
                    *   **试探分配**:
                        *   `Available = (1,6,2,2) - (1,2,2,2) = (0,4,0,0)`
                        *   `Allocation[2] = (1,3,5,4) + (1,2,2,2) = (2,5,7,6)`
                        *   `Need[2] = (2,3,5,6) - (1,2,2,2) = (1,1,3,4)`
                    *   **用新状态运行安全性算法**: `Work = (0,4,0,0)`, Need 和 Allocation 更新了 P2 的。
                    *   找 `Need[i] <= Work`:
                        *   P0: Need(0,0,1,2) <= (0,4,0,0)? No (1>0, 2>0).
                        *   P1: Need(1,7,5,0) <= (0,4,0,0)? No.
                        *   P2: Need(1,1,3,4) <= (0,4,0,0)? No.
                        *   P3: Need(0,6,5,2) <= (0,4,0,0)? No.
                        *   P4: Need(0,6,5,6) <= (0,4,0,0)? No.
                    *   找不到任何一个进程可以完成。**系统进入不安全状态**。
                    *   **结论**: 系统**不能**将资源分配给 P2。

    *   **死锁检测 (Deadlock Detection)**：允许死锁发生，但系统会定时检测，一旦发现死锁，则采取措施解除。
    *   **死锁解除 (Deadlock Recovery)**：
        *   **资源抢占**：从一个或多个死锁进程中抢占足够资源给其他进程使用。
        *   **进程终止**：强制终止一个或多个死锁进程。代价很大。可以按优先级、已执行时间、已用资源等选择牺牲者。
        *   **进程回退 (Rollback)**：让一个或多个进程回退到足以避免死锁的安全点。需要系统记录进程历史信息。

---

*处理机调度算法的计算和银行家算法是这部分的重难点和必考点。一定要亲手画甘特图、算指标，并理解银行家算法的两个核心过程（安全性检查和资源请求）。*

*接下来是存储管理，内容也很多，我们继续！*

---

### 第五部分：存储器管理 (对应 P8, P9 的题目)

内存是宝贵的资源，操作系统需要有效管理它，让多个进程能共享内存、安全运行，并提供足够大的地址空间。

**1. 存储器的层次结构 (对应 P8 Q1)**

*   **为什么需要层次结构？** 因为存储设备的速度、成本、容量之间存在矛盾。速度快的贵、容量小；容量大的便宜、速度慢。
*   **典型层次 (从快到慢，从小到大)**：
    *   **寄存器 (Registers)**：CPU内部，最快，容量最小。
    *   **高速缓存 (Cache)**：介于CPU和主存之间，速度快，容量较小。
    *   **主存储器 (Main Memory / RAM)**：程序和数据运行时存放的地方，速度较快，容量较大。
    *   **外存储器 / 辅助存储器 (Secondary Storage)**：如SSD、磁盘。容量大，速度慢，非易失（断电不丢失）。用于长期保存文件和作为虚拟内存的后备存储。
    *   **(磁带等)**：更慢、更大容量的离线存储。
*   **OS主要管理**：**主存** 和 **辅存** 的分配、回收、地址映射、保护。

**2. 地址重定位 (Relocation)**

*   **程序编译链接后**形成的是**逻辑地址 (Logical Address)** 或称为**虚拟地址 (Virtual Address)**，是从0开始的相对地址。
*   **程序装入内存后**，需要放在物理内存的某个位置，访问指令和数据时需要使用**物理地址 (Physical Address)**。
*   **重定位**：将逻辑地址转换为物理地址的过程。
    *   **静态重定位 (Static Relocation)**：程序**装入时**一次性完成地址转换。程序一旦装入内存**不能移动**。
    *   **动态重定位 (Dynamic Relocation) (对应 P8 Q7)**：地址转换推迟到**程序运行时**（访问指令或数据时）才进行。
        *   **为什么需要？** 允许程序在内存中**移动**（如内存压缩时），方便内存共享。
        *   **如何实现？** 需要**硬件支持**：设置一个**重定位寄存器 (Base Register)**，存放程序的**起始物理地址**。CPU执行指令访问逻辑地址 `addr` 时，硬件自动将其加上重定位寄存器的值，得到物理地址 `physical_addr = base + addr`。通常还有一个**界限寄存器 (Limit Register)**，存放程序的**长度**，用于地址保护：`if (addr >= limit) then trap; else physical_addr = base + addr;`。这个负责地址转换和保护的硬件单元称为**内存管理单元 (MMU, Memory Management Unit)**。

**3. 连续分配存储管理方式**

将用户进程存放在内存中一个**连续**的区域。

*   **单一连续区**：内存只放OS和一个用户程序。最简单，但资源利用率低。
*   **固定分区 (Fixed Partitioning)**：将内存预先划分为若干**大小固定**的分区。
    *   **优点**：简单易实现，开销小。
    *   **缺点**：**内部碎片 (Internal Fragmentation)**（分配给进程的分区大于其实际需求，分区内部有浪费）；分区大小限制了程序大小。
*   **动态分区 (Dynamic Partitioning)**：根据进程的**实际需求**，动态地从**空闲内存**中划分一个连续区域分配给它。
    *   **优点**：没有内部碎片（理论上），更灵活。
    *   **缺点**：**外部碎片 (External Fragmentation)**（随着进程装入、移出，内存中会出现许多**不连续**的小空闲块，虽然总空闲空间够，但无法分配给需要大连续空间的新进程）。
    *   **动态分区分配算法 (基于顺序搜索) (对应 P8 Q8)**：当需要为进程分配 `size` 大小的空间时，搜索**空闲分区链/表**：
        *   **首次适应 (First Fit)**：从链首开始查找，找到**第一个**能满足 `size` 的空闲分区。**优点**：简单快速，倾向于保留大空闲块在链尾。**缺点**：链首易产生小碎片。
        *   **下次适应 (Next Fit)**：从**上次查找结束的位置**开始查找。**优点**：空闲块分布更均匀，查找开销比首次适应小。**缺点**：可能缺乏大空闲块。
        *   **最佳适应 (Best Fit)**：查找**所有**空闲分区，选择能满足 `size` 且**大小最小**的那个。**优点**：能保留大空闲块。**缺点**：查找开销大，易产生**非常多难以利用的小碎片**。
        *   **最坏适应 (Worst Fit)**：查找**所有**空闲分区，选择**最大的**那个。从中分割一部分给进程，剩余的作为新的空闲块。**优点**：不易产生小碎片，剩余空闲块较大。**缺点**：查找开销大，缺乏大空闲块时不利。
    *   **空闲分区回收 (对应 P8 Q9)**：当进程释放内存时，需要将其空间与**相邻**的空闲分区合并，避免产生更多小碎片。有四种情况：
        1.  释放区**上方**是空闲区：与上方合并。
        2.  释放区**下方**是空闲区：与下方合并。
        3.  释放区**上、下方**都是空闲区：三者合并为一个。
        4.  释放区上、下方都不是空闲区（或都是进程）：独立成为新空闲区。

**4. 非连续分配存储管理方式：分页 (Paging)**

为了解决外部碎片问题，允许将进程的地址空间**分散**地装入内存中许多**不一定相邻**的物理块中。

*   **基本思想**：
    *   将进程的**逻辑地址空间**划分为若干大小相等的**页 (Page)**。
    *   将**物理内存**划分为若干与页大小相等的**帧 (Frame)** 或称为**物理块 (Physical Block)**。
    *   以**页**为单位进行分配，一个页可以装入**任意**一个空闲的物理帧中。
*   **页面大小 (Page Size) (对应 P8 Q18)**：通常是**2的幂** (如 4KB = 2^12)，便于地址转换。
    *   **选择考虑**：
        *   **太小**：页表会很大，占用内存多；页面换入换出效率低。
        *   **太大**：**内部碎片**会增大（最后一个页通常装不满）。
        *   需要权衡。
*   **地址结构**：逻辑地址分为两部分：**页号 (Page Number, p)** 和 **页内偏移 (Offset, d)**。
    *   如果逻辑地址空间大小 $2^m$，页面大小 $2^n$，则页号占 $m-n$ 位，偏移占 $n$ 位。
*   **页表 (Page Table) (对应 P8 Q19)**：实现从页号到物理帧号映射的数据结构。
    *   **作用**：记录进程的每个页存放在哪个物理帧中。
    *   **内容**：每个进程都有一个页表。页表由**页表项 (Page Table Entry, PTE)** 组成，每个页表项对应逻辑地址空间中的一个页。
        *   基本内容：**物理帧号 (Frame Number)**。
        *   还可能包含：**存在位/有效位 (Present/Valid Bit)**（标记该页是否在内存中）、**访问位 (Accessed Bit)**、**修改位 (Modified/Dirty Bit)**、**保护位 (Protection Bits)** (读/写/执行权限)等（这些在虚拟内存中更常用）。
    *   页表通常存放在**内存**中。**页表基址寄存器 (PTBR)** 指向当前进程页表的起始地址。
*   **地址变换过程 (逻辑地址 -> 物理地址) (对应 P8 习题1 计算)**：
    1.  从逻辑地址中分离出**页号 p** 和**页内偏移 d**。
    2.  用**页号 p** 作为索引，访问**内存中的页表** (地址 = PTBR + p * PTE大小)，找到对应的**页表项 PTE**。
    3.  从 PTE 中取出**物理帧号 f**。
    4.  **物理地址 = 物理帧号 f * 页面大小 + 页内偏移 d**。
    *   **P8 习题1 计算示例**：逻辑地址空间4页，每页2K字节 (2048 Bytes = 2^11)。逻辑地址 4688。
        *   页面大小 = 2048。
        *   页号 p = `floor(逻辑地址 / 页面大小)` = `floor(4688 / 2048)` = 2。
        *   页内偏移 d = `逻辑地址 % 页面大小` = `4688 % 2048` = 592。
        *   查页表（题目已给）：页号 2 对应的 内存块号（帧号）是 6。
        *   物理地址 = 帧号 * 页面大小 + 偏移 = `6 * 2048 + 592` = `12288 + 592` = **12880**。
    *   **地址变换示意图**：
        ```mermaid
        graph LR
            subgraph CPU
                LogicalAddr["逻辑地址 (p, d)"]
            end
            subgraph MMU
                PTBR["页表基址寄存器"]
                TLB["快表 (TLB)"]
                Adder1["加法器(+)"]
                Adder2["加法器(+)"]
                Splitter["地址分离"]
                PTE_Lookup["查页表/快表"]
                FrameCombiner["帧号偏移合并"]
            end
            subgraph Memory
                PageTable["页表"]
                PhysicalMem["物理内存"]
            end

            LogicalAddr -- "p, d" --> Splitter
            Splitter -- "页号 p" --> PTE_Lookup
            Splitter -- "偏移 d" --> FrameCombiner
            PTBR -- "页表基址" --> Adder1
            PTE_Lookup -- "页表项地址 = 基址 + p*大小" --> Memory(PageTable)
            Memory(PageTable) -- "PTE(帧号 f, ...)" --> PTE_Lookup
            PTE_Lookup -- "帧号 f" --> FrameCombiner
            FrameCombiner -- "物理地址 = f * 页大小 + d" --> PhysicalAddrOut("物理地址")

            %% Optional TLB path
            LogicalAddr -- "p, d" --> TLB
            TLB -- "快速查找 p" --> TLB_Result{{"命中?"}}
            TLB_Result -- "是 (直接获取帧号 f)" --> FrameCombiner
            TLB_Result -- "否 (访问内存页表)" --> PTE_Lookup

            PhysicalAddrOut --> Memory(PhysicalMem)

            style TLB fill:#ccf,stroke:#333
        ```
*   **硬件支持 (对应 P8 Q20)**：
    *   **页表寄存器 (PTBR, PTLR)**：存放页表基址和长度。
    *   **内存管理单元 (MMU)**：执行地址转换逻辑。
    *   **快表 (Translation Lookaside Buffer, TLB)**：为了加速地址转换，设置的一个高速缓存，存放最近访问过的页表项。访问时先查TLB，命中则直接得到帧号，无需访问内存中的页表。

**5. 非连续分配存储管理方式：分段 (Segmentation)**

*   **基本思想**：按程序的**逻辑结构**（如主程序段、子程序段、数据段、栈段等）划分地址空间，每个**段 (Segment)** 的长度**可以不同**。段是逻辑单位，对用户可见。
*   **地址结构**：逻辑地址分为两部分：**段号 (Segment Number, s)** 和 **段内偏移 (Offset, d)**。
*   **段表 (Segment Table)**：每个进程一个段表，每个段表项对应一个段。
    *   **内容**：**段基址 (Base)**（该段在物理内存中的起始地址）、**段限长 (Limit)**（该段的长度）、保护位等。
*   **地址变换过程 (对应 P9 习题2 计算)**：
    1.  从逻辑地址中分离出**段号 s** 和**段内偏移 d**。
    2.  用**段号 s** 访问**段表** (地址 = STBR + s * STE大小)，找到对应**段表项 STE**。
    3.  从 STE 中取出**段基址 Base** 和**段限长 Limit**。
    4.  **检查**：`if (d >= Limit)`，则发生**地址越界**中断。
    5.  **计算物理地址**：`Physical Address = Base + d`。
    *   **P9 习题2 计算示例**：32位地址，16位段内地址（偏移）。
        *   (1) 逻辑地址 10097 (十进制)。假设表示 (段号 s, 偏移 d)。如何划分？如果高16位是段号，低16位是偏移。10097 = `0x2771`。段号=0, 偏移=10097。
            *   查段表：段 0，Limit=10K=10240, Base=6K=6144。
            *   检查：偏移 10097 < Limit 10240 ? 是。
            *   物理地址 = Base + d = 6144 + 10097 = **16241**。
        *   (2) 逻辑地址 10054H (十六进制)。= `0x10054`。高16位段号 = 1。低16位偏移 = 0054H = 84 (十进制)。
            *   查段表：段 1，Limit=600, Base=4K=4096。
            *   检查：偏移 84 < Limit 600 ? 是。
            *   物理地址 = Base + d = 4096 + 84 = **4180**。

**6. 分页与分段的主要区别 (对应 P8 Q26)**

| 特征         | 分页 (Paging)                         | 分段 (Segmentation)                      |
| :----------- | :------------------------------------ | :--------------------------------------- |
| **单位**     | 页是**物理**单位                      | 段是**逻辑**单位                         |
| **大小**     | 页大小**固定**且由系统决定            | 段大小**不固定**，由程序逻辑结构决定     |
| **地址空间** | **一维** (逻辑地址连续)               | **二维** (段号, 段内偏移)                |
| **用户可见性** | 对用户**透明** (通常不可见)           | 对用户**可见**                           |
| **产生碎片** | **内部碎片** (页内)                   | **外部碎片** (段间)                      |
| **信息共享** | 页共享实现复杂，粒度粗                | 段共享方便，按逻辑单位共享 (如代码段)    |
| **信息保护** | 以页为单位，不如分段方便              | 以段为单位，更符合逻辑，保护更方便       |

*   **段页式 (Segmented Paging)**：结合两者优点。先分段，再将每个段分页。地址结构：(段号, 段内页号, 页内偏移)。需要段表和页表。管理开销更大。

---

*存储管理这部分概念很多，分页和分段的地址转换是核心，务必掌握计算方法和流程图。各种分配算法的原理和优缺点也要清楚。*

*下一站是虚拟存储器，这是建立在分页/分段基础上的重要技术。准备好了吗？*

---

### 第六部分：虚拟存储器 (Virtual Memory) (对应 P10, P11, P12, P13 的题目)

虚拟存储器技术使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

**1. 基本概念与特征 (对应 P10 Q3)**

*   **目标**：在物理内存有限的情况下，为用户提供**更大的逻辑地址空间**，并允许多个进程共享内存，提高内存利用率和多道程序度。
*   **核心思想**：**部分装入**和**请求调入**。程序运行时，无需将所有代码和数据都装入内存，只需装入当前需要的部分。当需要访问的部分不在内存时，再由OS负责从外存调入。
*   **特征**：
    *   **离散性 (Discreteness)**：程序地址空间可以分散存放在内存和外存。
    *   **多次性 (Multiplicity)**：程序运行所需的代码和数据可以分多次调入内存。
    *   **对换性 (Swapping)**：允许将内存中暂时不用的部分换出到外存。
    *   **虚拟性 (Virtuality)**：能够从逻辑上扩充内存容量，用户看到的虚拟内存空间可以远大于物理内存。
*   **最本质的特征**：**离散性**（或者说基于非连续分配）以及在此基础上的**多次性/对换性**，共同实现了逻辑上的**虚拟性**。简单说，就是**允许程序只装入部分并能动态增减在内存中的部分**的能力。

**2. 实现方式**

主要基于**分页**或**分段**，常用的是**请求分页 (Demand Paging)**。

*   **请求分页系统**：
    *   程序运行前，只将少量页（甚至0页）装入内存。
    *   当CPU访问的**页不在内存**中时，产生**缺页中断 (Page Fault)**。
    *   OS处理中断：
        1.  检查地址是否合法。
        2.  查找该页在外存（如磁盘交换区）的位置。
        3.  在内存中查找一个**空闲物理帧**。
        4.  **如果没有空闲帧**，则需要运行**页面置换算法 (Page Replacement Algorithm)**，选择一个**牺牲帧 (Victim Frame)**。
        5.  如果牺牲帧中的页被**修改过 (Dirty Bit = 1)**，则需先将其**写回外存**。
        6.  将所需的页从**外存读入**到找到的空闲帧或牺牲帧中。
        7.  **更新页表**（设置存在位=1，帧号，重置访问位/修改位等）。
        8.  **重新执行**被中断的指令。
*   **请求分段系统 (Demand Segmentation)**：类似，以段为单位调入调出，处理**缺段中断 (Segment Fault)**。

**3. 程序运行时的时空局限性 (对应 P10 Q2)**

虚拟存储技术的**可行性**依赖于程序的**局部性原理 (Principle of Locality)**：

*   **时间局限性 (Temporal Locality)**：程序中**最近被访问过**的指令或数据，**很可能**在不久的将来**再次被访问**。 (e.g., 循环中的代码和变量)
*   **空间局限性 (Spatial Locality)**：程序**访问了某个存储单元**后，**很可能**在不久的将来**访问其附近的存储单元**。 (e.g., 顺序执行的代码，数组元素)
*   **意义**：由于局部性原理，程序在**一段时间内**实际访问的**页面/段**通常**只占其总空间的一小部分**（称为**工作集 Working Set**）。因此，只需将这部分调入内存，就能让程序高效运行，从而支持虚拟存储。

**4. 请求分页系统中的页表结构 (对应 P10 Q6, P12 Q5(1))**

除了基本的帧号，页表项 (PTE) 至少还需要包含以下信息：

*   **状态位 / 存在位 (Status / Present Bit)**：指出该页是否在**内存**中。=1 在内存，=0 在外存。这是产生缺页中断的依据。
*   **访问位 (Accessed / Reference Bit)**：由**硬件**设置。当该页被访问（读或写）时，硬件自动将其置1。用于页面置换算法（如LRU的近似实现）。OS会定期清除此位。
*   **修改位 / 脏位 (Modified / Dirty Bit)**：由**硬件**设置。当该页被**写入**时，硬件自动将其置1。用于页面换出：如果此位为1，表示页内容已被修改，换出时**必须写回外存**；如果为0，表示未修改，可以直接丢弃（因为外存有最新副本），减少I/O开销。
*   **保护位 (Protection Bits)**：如 读/写/执行 权限。
*   **外存地址 (Disk Address)** (P12 Q5 辅存地址)：指出该页在外存交换区的位置（如果页不在内存中）。

**5. 地址变换过程 (对应 P10 Q8, P12 Q5, P13 Q7)**

与基本分页类似，但增加了对**存在位**的检查：

1.  分离逻辑地址得到 页号 p 和 偏移 d。
2.  查 TLB (快表)：
    *   命中，且权限允许 -> 得到帧号 f -> 物理地址 = f * 页大小 + d。**结束**。
    *   未命中 -> 继续。
3.  查内存中的页表 (基址+p*大小)：找到 PTE。
4.  **检查存在位 P**：
    *   **P=1 (在内存中)**：
        *   检查访问权限。非法则中断。
        *   合法 -> 取出帧号 f -> 物理地址 = f * 页大小 + d。
        *   更新访问位/修改位（硬件完成）。
        *   将 PTE 加入 TLB (可选)。**结束**。
    *   **P=0 (不在内存中)**：产生**缺页中断 (Page Fault)**。
        *   **转OS处理**：执行页面调入和置换逻辑 (如前述步骤)。
        *   处理完毕后，**返回**到被中断的指令**重新执行**第1步。

*   **P12 Q5 (2) 计算**：逻辑地址 0A10H -> 页号 2, 偏移 210H。查页表：页2，状态=1，块号=7。在内存。物理地址 = 7 * 1K + 210H = **1E10H** (7696 Decimal)。
*   **P12 Q5 (3) 现象**：指令寻址 C1CH (Hex) = 1100 0001 1100b。页号=1100b=12? 偏移=0011100b=28? 假设是访问**页3**。查页表：页3，状态=0。**发生缺页中断 (Page Fault)**。OS需要介入：① 找到牺牲页 (按LRU，看最近访问时间，牺牲页1)；② 若牺牲页修改过则写回；③ 从外存地址8000调入页3到牺牲帧；④ 更新页表项3；⑤ 重新执行指令。
*   **P13 Q7 (1) 计算**：逻辑地址 184BH -> 页号 1, 偏移 04BH。查页表：页1 -> 帧7。物理地址 = 7 * 1K + 04BH = **1C4BH**。
*   **P13 Q7 (2) 计算**：逻辑地址 5000 (Decimal) -> 页号 4, 偏移 896。查页表：页4 -> 帧12。物理地址 = 12 * 1K + 896 = **13184**。
*   **P13 Q7 (3) 现象**：访问 24A0H (Hex) = 9376 (Decimal)。页号 = floor(9376/1024) = 9。偏移 = 160。查页表：没有页号为 9 的表项。发生 **地址越界中断 (Addressing Error / Segmentation Fault)** 或视为**非法页引用 (Invalid Page Reference)**，这是一种程序错误。

**6. 页面置换算法 (Page Replacement Algorithms) (对应 P10 Q12, Q13; P11 Q2, Q3, Q4)**

当发生缺页中断且**没有空闲物理帧**时，需要选择一个当前在内存中的页（牺牲页）将其换出。目标是选择**未来最不可能被访问**的页，以减少未来的缺页率。

*   **FIFO (First-In, First-Out)**：选择**最早进入内存**的页作为牺牲页。
    *   **实现**：用一个队列记录页进入内存的顺序。
    *   **优点**：简单易实现。
    *   **缺点**：性能较差，可能换出常用页。存在 **Belady 异常**：对于某些页面引用序列，增加分配的物理帧数反而导致缺页次数**增加** (如 P10 Q13 所示)。
    *   **计算 (P10 Q13, P11 Q2, Q3, Q4)**：维护一个定长（帧数 M）的队列或数组。缺页时，若未满，新页入队尾；若已满，队首页（最早进入的）出队，新页入队尾。
*   **LRU (Least Recently Used)**：选择**最近最长时间未被使用**的页作为牺牲页。基于局部性原理，认为最近没用的页，将来可能也不用。
    *   **实现**：需要记录每个页的**上次访问时间**。通常用两种方式近似：
        *   **计数器 (Counters)**：每个页表项关联一个时间戳寄存器，每次访问更新为当前时间。置换时查找时间戳最小的页。开销大。
        *   **栈 (Stack)**：维护一个按访问时间排序的页号栈。访问某页时，将其移到栈顶。栈底即为LRU页。开销也较大。
        *   **近似LRU（常用）**：利用页表项中的**访问位 (Reference Bit)**。
            *   **Clock (时钟/二次机会) 算法**：将内存中的页组织成环形链表，有一个指针。缺页时，从指针处开始扫描：
                *   检查当前页访问位。若为 0，则选择该页替换，指针前移。
                *   若为 1，则将其**置 0**，指针**前移**，继续检查下一页（给了第二次机会）。
            *   **增强型 Clock / NRU (Not Recently Used)**：同时考虑**访问位(A)**和**修改位(M)**。将页分为4类：(0,0)未访问未修改，(0,1)未访问已修改，(1,0)已访问未修改，(1,1)已访问已修改。优先替换 (0,0) 类。
    *   **优点**：性能好，接近最优算法 OPT。
    *   **缺点**：硬件支持（访问位）和软件实现开销比 FIFO 大。
    *   **计算 (P11 Q2, Q3)**：精确 LRU 需要跟踪每个页的**最后访问时刻**。缺页时，在当前内存中的页里，选择最后访问时刻最早的那个替换。
*   **OPT / MIN (Optimal)**：选择**未来最长时间不会被访问**的页作为牺牲页。
    *   **实现**：无法实现，因为需要预知未来。
    *   **用途**：作为性能评价的**基准**，衡量其他算法的优劣。

*   **计算示例回顾**：
    *   **P10 Q13 (FIFO)**: M=3, Faults=9; M=4, Faults=10. (Belady's Anomaly)
    *   **P11 Q2 (FIFO vs LRU)**: Frames=4, Init=[1,2,3,4]. Seq: (H)(H)5(F,R1) 6(F,R2) 2(F,R3) 1(F,R4) (H) 3(F,R5) 7(F,R6). FIFO Faults=6. LRU: (H)(H)5(F,R3) 6(F,R4) 2(H) 1(H) (H) 3(F,R5) 7(F,R6). LRU Faults=4.
    *   **P11 Q3 (FIFO vs LRU)**: Frames=3, Init=[0]. Seq(Page): 1,2,1,0,4,1,3,4,2,1. FIFO Faults=5. LRU Faults=7. (注意LRU有时可能比FIFO差)
    *   **P11 Q4 (FIFO)**: M=3, Faults=7; M=4, Faults=5. (正常情况，帧多->缺页少)

**7. 抖动 (Thrashing) (对应 P10 Q18, Q20)**

*   **现象**：系统花费**大量时间**在页面换入换出上，导致 CPU 利用率**急剧下降**。
*   **原因 (P10 Q18)**：分配给进程的**物理帧数太少**，无法容纳其**工作集 (Working Set)**（进程在某段时间内频繁访问的页面集合），导致进程运行几条指令就**频繁发生缺页中断**。系统可能误认为CPU空闲而调入更多进程，使问题恶化。
*   **防止方法 (P10 Q20)**：
    *   **控制多道程序度**：使用**中级调度**，当发现抖动时，挂起一些进程。
    *   **工作集模型 (Working Set Model)**：OS 跟踪每个进程的工作集，并为其分配足够的帧数。如果内存不足，则不启动新进程或挂起某些进程。
    *   **缺页率控制 (Page Fault Frequency, PFF)**：监控每个进程的缺页率。如果**过高**，说明缺帧，尝试分配更多帧；如果**过低**，说明帧有多余，可以回收一些。设定一个缺页率的上限和下限。
    *   **采用**更有效的**局部页面置换策略** (Local Replacement, 只在进程自己的帧里置换)，而不是全局策略 (Global Replacement, 可以置换系统中任何进程的帧)。

**8. 影响页面换入换出效率的因素 (对应 P10 Q16)**

*   **页面置换算法**：直接影响缺页率。
*   **分配给进程的物理帧数**：太少易抖动，太多浪费内存。
*   **页面大小**：影响内外碎片、页表大小、I/O效率。
*   **程序编写方式**：程序的局部性好坏直接影响缺页率。
*   **外存（交换区）的读写速度**：直接影响换入换出的时间。

**9. 请求分段系统的硬件支持 (对应 P10 Q22)**

类似请求分页，段表项 (STE) 需要增加：

*   **存在位 (Present Bit)**：段是否在内存。
*   **修改位 (Modified Bit)**：段是否被修改。
*   **访问位 (Accessed Bit)**：段是否被访问。
*   **外存地址 (Disk Address)**：段在外存的位置。

---

*虚拟存储是现代OS的基石。理解缺页中断处理流程、页面置换算法（特别是FIFO和LRU的计算）以及抖动现象是关键。*

*接下来是I/O系统和文件管理，我们继续！*

---

### 第七部分：输入输出 (I/O) 系统 (对应 P14 的题目)

这部分关注 OS 如何管理各种 I/O 设备，并为用户提供方便、统一、高效的接口。

**1. 设备无关性 (Device Independence) (对应 P14 Q4, Q18)**

*   **含义 (Q4, Q18)**：用户或应用程序使用 I/O 设备时，**无需关心具体的物理设备**。应用程序使用**逻辑设备名** (Logical Device Name) 或抽象命令 (如 `read`, `write`) 来访问设备，而由 OS 负责将这些请求映射到具体的物理设备操作上。
*   **为什么要设置层次结构 (Q4)?** 为了实现设备无关性，OS 的 I/O 软件通常采用层次结构：
    *   **用户层软件**：发出抽象 I/O 请求 (如 `read(fileID, buffer, length)`)。
    *   **设备无关操作系统软件**：处理逻辑设备名到物理设备名的映射；进行设备分配与回收；提供统一的接口（如块设备接口、字符设备接口）；进行缓冲管理；错误处理。**这是实现设备无关性的关键层**。
    *   **设备驱动程序 (Device Drivers)**：与特定设备控制器交互，将上层传来的抽象请求（如读写逻辑块号）转换为具体的设备命令（如设置控制器寄存器），并处理设备中断。屏蔽了设备的物理细节。
    *   **中断处理程序 (Interrupt Handlers)**：捕获设备发来的中断信号，进行初步处理，唤醒等待中断的驱动程序进程。
    *   **硬件 (Hardware)**：包括设备本身和设备控制器。
    *   **好处**：易于添加新设备（只需写新驱动）；提高软件可移植性；简化用户编程。
*   **如何实现独立性 (Q18)?** 主要通过：
    *   **逻辑设备表 (LUT)**：将用户使用的逻辑设备名映射到物理设备。
    *   **设备驱动程序**：为每类设备提供统一接口，隐藏硬件差异。
    *   **文件系统**：将设备视为特殊文件，使用统一的文件操作接口访问。

**2. I/O 控制方式 (对应 P14 Q16)**

指 CPU 控制 I/O 操作完成数据传输的方式。

*   **程序查询 (Programmed I/O)**：
    *   **过程**：CPU 向 I/O 控制器发出命令后，**反复查询**控制器的状态寄存器，直到设备准备好，然后 CPU 负责**逐字**将数据在内存和设备控制器间传送。
    *   **优缺点**：实现简单；但 CPU **忙等 (Busy-Waiting)**，效率极低。
    *   **适用场合**：早期系统；或 CPU 速度远低于 I/O 速度且无事可做的嵌入式系统；或初始化等简单交互。
*   **中断驱动 (Interrupt-driven I/O)**：
    *   **过程**：CPU 发出 I/O 命令后，**转去执行其他任务**。当 I/O 设备准备好或操作完成时，控制器通过**中断信号**通知 CPU。CPU 响应中断，保存现场，执行**中断服务程序**完成数据传输（通常仍是 CPU 逐字传送）或处理，然后恢复现场。
    *   **优缺点**：CPU 无需忙等，效率**大大提高**；但每次中断处理有开销，对于高速设备、大量数据传输，中断频繁，开销仍较大。
    *   **适用场合**：绝大多数中低速设备。
*   **DMA (Direct Memory Access)**：
    *   **过程**：CPU 只需向 **DMA 控制器 (DMAC)** 发出 I/O 请求（包括设备地址、内存缓冲区地址、数据量、读/写方向）。之后，DMAC **完全接管**总线，**直接**在设备和内存之间传输数据，**无需 CPU 干预**。传输完成后，DMAC **通过中断**通知 CPU。
    *   **优缺点**：**进一步减少** CPU 开销，特别适合高速设备和**批量数据**传输；需要额外硬件 DMAC。
    *   **适用场合**：磁盘、固态硬盘、网卡、显卡等高速设备。
*   **通道控制 (Channel Control)**：（大型机、早期技术）引入**通道处理器**，能执行更复杂的 I/O 程序（通道指令），进一步解放 CPU。可以看作更强大的 DMAC。

**3. DMA 工作流程 (对应 P14 Q17)**

1.  **初始化**：进程请求 I/O，CPU (通过驱动程序) 对 DMAC 进行编程：设置源地址（内存/设备）、目标地址（设备/内存）、传送字节数、传送模式（单字节/块/突发）等控制信息到 DMAC 的寄存器中。
2.  **启动 DMA**：CPU 向 DMAC 发出启动命令，然后 CPU **继续执行其他进程**。
3.  **数据传送**：DMAC 向总线仲裁器请求总线使用权。获得总线后，DMAC 控制设备与内存间的数据传输。
    *   **周期窃取 (Cycle Stealing)**：DMAC 在 CPU 不访问内存总线的间隙（或强制 CPU 暂停一个总线周期）传输一个字/字节。对 CPU 影响小。
    *   **突发模式 (Burst Mode)**：DMAC 获得总线后连续传输一批数据，期间 CPU 无法使用总线。传输效率高，但可能阻塞 CPU 较长时间。
4.  **传送计数**：每传送一个单位数据，DMAC 内部的计数器递减（或地址递增）。
5.  **结束与中断**：当计数器为 0 时，表示数据传送完毕。DMAC **向 CPU 发送中断信号**，通知操作完成。CPU 响应中断，进行后续处理（如通知进程）。

**4. 引入缓冲 (Buffering) 的主要原因 (对应 P14 Q24)**

在 I/O 操作中设置缓冲区（内存中的一块区域）是为了：

*   **缓和 CPU 与 I/O 设备速度不匹配的矛盾**：例如，高速 CPU 产生数据远快于慢速打印机打印，缓冲区可以暂存数据。反之，高速 CPU 处理数据远快于慢速键盘输入，缓冲区可以积累输入。
*   **减少对 CPU 的中断频率，放宽对 CPU 中断响应时间的限制**：可以将数据在缓冲区积攒到一定量再进行传输或处理，减少中断次数。
*   **提高 CPU 和 I/O 设备之间的并行性**：CPU 可以向缓冲区写入（或读取）数据的同时，I/O 设备可以从缓冲区读取（或写入）数据，实现 C P U 计算和 I / O 操作的并行。例如，双缓冲 (Double Buffering)，CPU 使用一个缓冲区时，设备使用另一个。
*   **匹配数据单元大小不一致**：例如网络传输的数据包大小与应用程序处理的数据块大小可能不同，缓冲区可以进行数据的拆分和重组。

**5. SPOOLing 技术 (Simultaneous Peripheral Operations On-Line) (对应 P14 Q21, Q22, Q23)**

*   **实质 (Q21)**：一种**外设联机操作**技术，利用**磁盘**作为高速**缓冲区**，将低速、独占的 I/O 操作（如打印）转换为高速的磁盘读写操作，从而**虚拟化**设备，使其看起来像是可共享、并发使用的。
*   **关键技术 (Q21)**：
    *   **高速磁盘缓冲区**：在外存上开辟**输入井 (Input Spool)** 和**输出井 (Output Spool)**。
    *   **输入/输出进程 (Daemon)**：专门负责将数据从输入设备传送到输入井，或从输出井传送到输出设备。
    *   **多道程序技术**：OS 底层支持。
*   **为请求 I/O 的进程提供的服务 (Q22)**：
    *   **接收 I/O 请求**：用户进程发出打印请求时，SPOOLing 系统接管。
    *   **数据缓冲**：将用户要打印的数据高速地写入到磁盘上的**输出井**中，形成一个个打印作业文件。
    *   **作业调度**：管理输出井中的打印作业队列，按一定策略（如 FCFS）选择下一个要打印的作业。
    *   **设备控制**：由专门的输出进程负责从输出井读取作业文件内容，并控制**物理打印机**进行实际打印。
    *   **状态反馈**：向用户提供作业状态信息（等待、打印中、完成等）。
*   **共享打印机的基本思想 (Q23)**：
    1.  用户进程 A 请求打印，它并**不直接**访问打印机。
    2.  SPOOLing 系统（通常是打印服务进程）将进程 A 要打印的数据**写入**到磁盘上的**输出井**中，为其创建一个打印作业。进程 A 可以**立即**继续执行其他任务，感觉打印很快就“完成”了。
    3.  其他用户进程 B、C 也可以同时请求打印，它们的数据也被写入输出井，形成排队的打印作业。
    4.  后台运行的**打印机守护进程 (Printer Daemon)** 按照队列顺序，从输出井中取出**一个**完整的打印作业。
    5.  该守护进程**控制物理打印机**，将取出的作业数据实际打印出来。
    6.  打印完成后，守护进程再从输出井取下一个作业。
    *   **效果**：将独占的打印机虚拟成了可供多个用户并发请求的共享设备，提高了打印效率和设备利用率。

**6. 磁盘访问时间 (Disk Access Time) (对应 P14 Q30)**

完成一次磁盘读/写操作所需的时间，主要由三部分组成：

*   **寻道时间 (Seek Time, Ts)**：将磁头臂移动到**目标磁道 (Cylinder)** 所需的时间。这是**最主要**的部分，通常耗时几毫秒到几十毫秒。与移动距离有关。
*   **旋转延迟时间 (Rotational Latency, Tr)**：等待磁盘旋转，使**目标扇区**转到磁头下方所需的时间。平均为旋转一周时间的一半。取决于磁盘转速（如 7200 RPM）。
*   **传输时间 (Transfer Time, Tt)**：数据实际从磁盘读出或写入所需的时间。取决于要传输的数据量和磁盘传输速率（转速、位密度）。
*   **总时间** ≈ Ts + Tr + Tt (+ 控制器处理时间 + 排队等待时间)

**7. 磁盘调度算法 (Disk Scheduling Algorithms) (对应 P14 Q31)**

目标：**减少总寻道时间**（即减少磁头臂移动的总距离），提高磁盘 I/O 效率。

*   **FCFS (先来先服务)**：按请求到达的顺序处理。
    *   **优点**：公平。
    *   **缺点**：磁头臂移动可能非常随机和低效，平均寻道时间长。
*   **SSTF (最短寻道时间优先)**：选择与磁头当前位置**寻道距离最短**的那个请求进行服务。
    *   **优点**：性能较好，平均寻道时间短。
    *   **缺点**：可能导致**饥饿**现象，即某些远离磁头位置的请求长时间得不到服务。
*   **SCAN (扫描 / 电梯算法)**：磁头在一个方向上移动（如从内到外），服务所有沿途的请求，到达**磁盘末端**后反向移动，服务沿途请求。
    *   **优点**：克服了 SSTF 的饥饿问题；寻道性能较好；考虑了方向。
    *   **缺点**：对两端的请求不利（刚经过又要等很久）；磁头必须到末端才回头（即使后面没有请求）。
*   **C-SCAN (循环扫描)**：磁头只在一个方向上（如从内到外）服务请求。到达末端后，**立即快速返回**到起始端，**途中不服务**任何请求，然后重新开始扫描。
    *   **优点**：比 SCAN 提供**更均匀的等待时间**。
    *   **缺点**：返回时不服务，有一定开销。
*   **LOOK / C-LOOK**：SCAN / C-SCAN 的改进版。磁头移动到**该方向上最后一个请求**处即改变方向（LOOK）或快速返回（C-LOOK），**不必**移动到磁盘的物理末端。是实践中常用的算法。
*   **各算法优先考虑的问题 (Q31)**：
    *   **FCFS**：请求的**到达时间**。
    *   **SSTF**：与当前磁头位置的**寻道距离**。
    *   **SCAN / LOOK**：当前**移动方向**上的下一个最近请求。
    *   **C-SCAN / C-LOOK**：当前**扫描方向**上的下一个请求。

---

*I/O 管理这部分，重点理解设备无关性、I/O 控制方式（特别是 DMA）、SPOOLing 技术和磁盘调度算法（特别是计算磁头移动距离）。*

*最后一部分是文件管理，我们一鼓作气完成它！*

---

### 第八部分：文件管理 (对应 P15 的题目)

文件系统是 OS 中负责管理外存（主要是磁盘）上的信息（文件），并提供用户方便访问接口的部分。

**1. 文件的逻辑结构与物理结构 (对应 P15 Q6)**

*   **逻辑结构 (Logical Structure)**：从**用户角度**看到的文件组织形式，是用户可以直接处理的数据结构。独立于物理存储。
    *   **无结构文件 (流式文件 Stream File)**：文件被看作一个**字节序列**。如 Unix/Linux 中的文件。用户自行解释内容。最简单灵活。
    *   **有结构文件 (记录式文件 Record File)**：文件由若干**记录**组成。
        *   **顺序文件 (Sequential File)**：记录按顺序存储和访问。可以是定长或变长记录。
        *   **索引文件 (Indexed File)**：为文件建立**索引表**，通过索引可以快速定位记录（随机访问）。
        *   **索引顺序文件 (Indexed Sequential File)**：结合两者，既可顺序访问，也可通过索引随机访问。
        *   **(直接文件 / 散列文件)**：通过关键字计算记录的物理地址，实现快速直接访问。
*   **物理结构 (Physical Structure) / 文件分配方式 (File Allocation)**：文件数据在**外存（磁盘）**上的存放方式和组织结构。OS 层面关心。
    *   **连续分配 (Contiguous Allocation)**：为文件分配**一组连续的**物理块。
        *   **优点**：支持顺序访问和随机访问，速度快。
        *   **缺点**：**外部碎片**；文件**创建时**需指定大小（不易扩展）；文件大小受限于最大连续空闲区。
    *   **链接分配 (Linked Allocation)**：文件数据存放在**不连续**的物理块中，通过**指针**将属于同一文件的块链接起来。
        *   **优点**：**无外部碎片**；文件可以**动态增长**。
        *   **缺点**：**只支持顺序访问**（随机访问效率低，需从头遍历）；指针占用空间；可靠性差（指针丢失导致文件数据丢失）。
        *   **FAT (File Allocation Table)**：将所有块的链接指针集中存放在文件分配表中（内存或磁盘特定区域）。是链接分配的一种常用变体。改善了随机访问性能和可靠性。
    *   **索引分配 (Indexed Allocation)**：为每个文件设置一个**索引块 (Index Block)**，其中包含了指向该文件**所有数据块**的指针（地址）。
        *   **优点**：**无外部碎片**；文件可**动态增长**；**支持随机访问**。
        *   **缺点**：索引块本身需要存储空间（开销）；对于小文件，索引块开销比例可能很大。
        *   **改进方案**：
            *   **链接索引**：如果一个索引块不够，可以将多个索引块链接起来。
            *   **多级索引 (Multilevel Index)**：索引块中存放的不是数据块地址，而是下一级索引块的地址。适用于大文件。
            *   **混合索引 (Combined Indexing)**：如 Unix inode。索引节点中包含少量直接指针、一级间接指针、二级间接指针等，兼顾小文件和大文件的效率。

**2. 文件类型（按组织方式）(对应 P15 Q7)**

这通常指文件的**逻辑结构**或**访问方式**。常见类型：

*   **普通文件 (Ordinary Files)**：包含用户信息（文本、代码、数据等）。可以是流式或记录式。
*   **目录文件 (Directory Files)**：包含文件目录信息（文件名、属性、物理地址等）。由系统使用。
*   **特殊文件 (Special Files)**：用于 I/O 设备。将设备映射为文件，允许用户用文件操作接口访问设备。
    *   **块特殊文件 (Block Special Files)**：用于块设备（如磁盘）。
    *   **字符特殊文件 (Character Special Files)**：用于字符设备（如键盘、打印机）。

**3. 目录管理的要求 (对应 P15 Q14)**

目录（或文件夹）用于组织和管理文件。对目录管理的主要要求：

*   **实现“按名存取”**：用户通过文件名就能方便地找到和访问文件。
*   **提高检索速度**：能够快速地在目录中查找文件。
*   **文件共享**：允许不同用户共享文件。
*   **文件保护**：能够对文件进行访问控制。
*   **允许文件重名**：在不同目录下允许存在同名文件。
*   **提供**方便的**文件操作**：创建、删除、列目录、修改属性等。

**4. 目录结构 (对应 P15 Q16)**

*   **单级目录 (Single-Level Directory)**：所有文件都在同一个目录下。
    *   **优点**：简单。
    *   **缺点**：**不允许重名**；文件查找效率低（当文件很多时）；无法组织文件。
*   **两级目录 (Two-Level Directory)**：有一个**主文件目录 (MFD)**，下面为每个用户建立一个**用户文件目录 (UFD)**。
    *   **优点**：解决了**重名**问题（不同用户目录下可同名）；提供了一定保护。
    *   **缺点**：用户间共享文件不方便；组织结构仍不够灵活。
*   **树形结构目录 (Tree-Structured Directory)**：**目前广泛采用**。有一个**根目录**，每个目录下可以包含文件或其他目录（子目录）。
    *   **优点**：**层次清晰**，便于文件分类组织；解决了重名问题（不同路径下可同名）；查找效率较高（相对单/两级）；便于实现访问控制和共享。
    *   **缺点**：查找文件需要指定**路径**；共享实现相对复杂（如下）。
*   **无环图目录结构 (Acyclic-Graph Directory)**：在树形结构基础上，允许目录或文件有**多个父目录**，即允许**共享**。通过**链接 (Link)** 实现。
    *   **优点**：**方便文件共享**。
    *   **缺点**：管理**更复杂**（如删除文件时需处理所有链接，可能产生悬空指针）；需要机制避免循环（如只允许链接文件，不允许链接目录，或检测环）。
*   **(通用图结构)**：允许出现环。非常复杂，很少使用。

**5. 路径名和当前目录 (对应 P15 Q17)**

在树形或图结构目录中定位文件/目录的方式：

*   **路径名 (Pathname)**：从根目录或当前目录出发，到达目标文件/目录所经过的**一串目录名**。
    *   **绝对路径名 (Absolute Pathname)**：从**根目录**开始的完整路径。在任何位置都唯一确定一个文件。 (e.g., `/usr/bin/gcc`, `C:\Windows\System32\cmd.exe`)
    *   **相对路径名 (Relative Pathname)**：从**当前目录 (Current Directory / Working Directory)** 开始的路径。更简洁常用。 (e.g., `../src/main.c`, `docs/report.txt`)
*   **当前目录 (Current Directory)**：每个进程都有一个相关联的“当前位置”。用户可以通过命令 (如 `cd`) 改变当前目录。OS 使用当前目录来解析相对路径名。

**6. 文件共享的实现 (基于符号链) (对应 P15 Q22, Q23)**

在图结构目录中实现文件共享，常用**链接 (Link)** 技术。

*   **硬链接 (Hard Link)**：（虽然题目没直接问，但对比有助于理解）多个目录项直接指向**同一个文件索引节点 (inode)**。文件只有一个物理副本。只有当链接计数（指向该 inode 的目录项数量）减为 0 时，文件才被真正删除。
    *   **优点**：高效，无额外开销。
    *   **缺点**：通常不能跨文件系统；不能链接目录（易造成循环）。
*   **符号链接 (Symbolic Link / Soft Link)**：创建一个**特殊类型的文件**，其内容是**指向目标文件/目录的路径名**。
    *   **实现 (Q22)**：用户 B 想共享用户 A 的文件 `f`，可以在 B 的目录下创建一个符号链接 `l`，`l` 的内容就是 `f` 的路径名（绝对或相对）。当访问 `l` 时，OS 识别出是符号链接，读取其内容（路径名），然后**根据该路径名再去查找**目标文件 `f`。
    *   **主父目录 vs 链接父目录 (Q22)**：文件 `f` 本身只有一个 inode，它记录了文件的元数据。最初创建 `f` 的目录 `/A` 是它的一个父目录。符号链接 `l` 所在的目录 `/B` 可以看作是通过链接产生的另一个“逻辑上”的父目录关系。但 `l` 和 `f` 是两个独立的文件（inode 不同）。
    *   **优点 (Q23)**：
        *   可以**跨文件系统**进行链接。
        *   可以**链接目录**。
        *   实现**灵活**。
    *   **缺点**：
        *   访问时需要**额外的路径解析**开销。
        *   存在**悬空指针 (Dangling Pointer)** 问题：如果目标文件 `f` 被删除或移动，符号链接 `l` 仍然存在，但指向一个无效路径，访问 `l` 会失败。

---

**总结**

同学，我们已经把这些练习题涉及到的操作系统核心知识点都梳理了一遍。内容确实不少，涵盖了 OS 的方方面面：

*   **基础概念**：OS目标、作用、特征、发展。
*   **进程与线程**：概念、状态、同步互斥（P/V操作是重点！）、线程优势。
*   **调度**：三级调度、调度目标、各种作业/进程调度算法（计算是重点！）。
*   **死锁**：原因、条件、预防、避免（银行家算法是重点！）。
*   **内存管理**：分区、分页、分段、地址转换（计算是重点！）。
*   **虚拟内存**：概念、请求分页、页面置换算法（FIFO/LRU计算是重点！）、抖动。
*   **I/O管理**：设备无关性、控制方式（DMA）、缓冲、SPOOLing、磁盘调度。
*   **文件管理**：逻辑/物理结构、目录结构、文件共享（链接）。

**下一步建议**：

1.  **消化理解**：对照笔记，重新阅读教材或参考资料，确保理解每个概念的含义、原理和联系。
2.  **动笔实践**：对于计算题（调度算法、页面置换、银行家算法、地址转换），务必**亲手做几遍**，熟练掌握计算过程和技巧。画甘特图、列表格是好方法。
3.  **回顾题目**：现在，尝试**独立**完成你发来的这些练习题。看看哪些知识点掌握了，哪些还有疑问。
4.  **查漏补缺**：对于做错或不确定的题目，回过头来看对应的知识点讲解，或者向我提问。我们可以针对性地深入探讨。
5.  **构建体系**：尝试画出知识点之间的联系图（思维导图），比如进程管理和内存管理如何关联，虚拟内存如何建立在分页之上等，形成整体认识。

你的目标是90分，这需要扎实的基础和熟练的应用能力。不要怕困难，一步一个脚印，多思考、多练习，你一定能做到！

如果在学习过程中遇到任何问题，随时都可以向我提问。我会尽力帮助你理解透彻。加油！